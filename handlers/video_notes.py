"""
–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤–∏–¥–µ–æ-–∫—Ä—É–∂–∫–æ–≤ (Video Note) —Å –∞–Ω–∞–ª–∏–∑–æ–º –µ–¥—ã
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤ –∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –∞—É–¥–∏–æ
"""

import asyncio
import tempfile
import aiohttp
import logging
import base64
import json
import re
from pathlib import Path
from typing import Optional, List, Dict, Any
from telegram import Update
from telegram.ext import ContextTypes

from modules.video_analysis import (
    KeyFrameExtractor,
    AudioContextParser,
    VideoAnalyzer,
    EvidenceAggregator
)

logger = logging.getLogger(__name__)


class VideoNoteAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –≤–∏–¥–µ–æ-–∫—Ä—É–∂–∫–æ–≤ —Å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º –∫–∞–¥—Ä–æ–≤ –∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–µ–π"""
    
    def __init__(self, config, openrouter_client=None):
        self.config = config
        self.openrouter_client = openrouter_client
        self.speech_to_text_url = "https://api.openrouter.ai/v1/audio/transcriptions"
        
        # Initialize new analysis modules
        self.keyframe_extractor = KeyFrameExtractor(target_frames=5)
        self.audio_parser = AudioContextParser(config=config, use_mock=False)  # Real audio transcription
        self.video_analyzer = VideoAnalyzer(config)
        self.evidence_aggregator = EvidenceAggregator()
    
    async def analyze_video_note(self, video_bytes: bytes, user_id: int) -> Optional[Dict[str, Any]]:
        """
        –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ-–∫—Ä—É–∂–∫–∞: –∫–∞–¥—Ä—ã + –∞—É–¥–∏–æ
        
        NEW PIPELINE:
        1. Extract audio hypothesis (what user said)
        2. Extract best keyframes (intelligent selection)
        3. Analyze each frame with hypothesis context
        4. Aggregate evidence from all frames + audio
        
        Returns dict with:
        - analysis: final analysis result
        - frames: list of extracted frame images (bytes)
        - transcription: audio transcription text
        """
        try:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–∏–¥–µ–æ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            with tempfile.NamedTemporaryFile(suffix='.mp4', delete=False) as tmp_file:
                tmp_file.write(video_bytes)
                video_path = tmp_file.name
            
            try:
                logger.info("=== Starting NEW video analysis pipeline ===")
                
                # STEP 1: Extract audio hypothesis
                logger.info("Step 1: Extracting audio hypothesis...")
                audio_hypothesis = await self.audio_parser.extract_hypothesis(video_path)
                logger.info(f"Audio hypothesis: {audio_hypothesis}")
                
                # STEP 2: Extract best keyframes
                logger.info("Step 2: Extracting keyframes...")
                frames = await self.keyframe_extractor.process(video_path)
                if not frames:
                    logger.error("Failed to extract keyframes")
                    return None
                logger.info(f"Extracted {len(frames)} keyframes")
                
                # STEP 3: Analyze frames with hypothesis context
                logger.info("Step 3: Analyzing frames with hypothesis...")
                visual_evidence = await self.video_analyzer.analyze_frames(
                    frames, 
                    audio_hypothesis
                )
                if not visual_evidence:
                    logger.error("Failed to analyze frames")
                    return None
                logger.info(f"Analyzed {len(visual_evidence)} frames")
                
                # STEP 4: Aggregate all evidence
                logger.info("Step 4: Aggregating evidence...")
                final_analysis = await self.evidence_aggregator.aggregate(
                    audio_hypothesis,
                    visual_evidence
                )
                
                logger.info("=== Analysis complete ===")
                logger.info(f"Final result: {final_analysis.get('dish_name')}, "
                          f"{final_analysis.get('calories_total')} kcal")
                
                # Add metadata
                final_analysis['frames_count'] = len(frames)
                
                # Return analysis + frames + transcription
                return {
                    'analysis': final_analysis,
                    'frames': frames,
                    'transcription': audio_hypothesis.get('transcription', '')
                }
                
            finally:
                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                Path(video_path).unlink(missing_ok=True)
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤–∏–¥–µ–æ: {e}", exc_info=True)
            return None



class MockVideoNoteAnalyzer:
    """–ú–æ–∫-–≤–µ—Ä—Å–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –±–µ–∑ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤–∏–¥–µ–æ"""
    
    async def analyze_video_note(self, video_bytes: bytes, user_id: int) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–æ–∫-–¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        return {
            "dish_name": "–ö–∞—Ä—Ç–æ—Ñ–µ–ª—å–Ω–æ–µ –ø—é—Ä–µ —Å —Ö–ª–µ–±–æ–º –∏ —á–∞–µ–º",
            "components": [
                {
                    "name": "–ö–∞—Ä—Ç–æ—Ñ–µ–ª—å–Ω–æ–µ –ø—é—Ä–µ",
                    "weight_g": 400,
                    "calories": 320,
                    "protein_g": 8,
                    "fat_g": 12,
                    "carbs_g": 52,
                    "confidence": 0.85
                },
                {
                    "name": "–•–ª–µ–± –±–µ–ª—ã–π",
                    "weight_g": 80,
                    "calories": 200,
                    "protein_g": 6,
                    "fat_g": 2,
                    "carbs_g": 40,
                    "confidence": 0.75
                },
                {
                    "name": "–ß–∞–π —Å —Å–∞—Ö–∞—Ä–æ–º",
                    "weight_g": 200,
                    "calories": 40,
                    "protein_g": 0,
                    "fat_g": 0,
                    "carbs_g": 10,
                    "confidence": 0.70
                }
            ],
            "weight_grams": 680,
            "calories_total": 560,
            "calories_per_100g": 82,
            "protein_g": 14,
            "fat_g": 14,
            "carbs_g": 102,
            "health_score": 6,
            "warnings": [
                "–ú–Ω–æ–≥–æ —É–≥–ª–µ–≤–æ–¥–æ–≤ (102–≥)",
                "–ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –±–µ–ª–∫–∞ (–∫—É—Ä–∏—Ü–∞, —Ä—ã–±–∞)"
            ],
            "audio_transcription": "–ø—é—Ä–µ –¥—É–º–∞—é –∑–¥–µ—Å—å 500–≥ –∏ –Ω–∞–≤–µ—Ä–Ω–æ–µ –µ—â–µ —Ö–ª–µ–±–∞ —Å—ä–µ–º –¥–≤–∞ –∫—É—Å–æ—á–∫–∞ –ø–ª—é—Å —á–∞–π",
            "frames_count": 5,
            "source": "video_note"
        }


async def handle_video_note(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤–∏–¥–µ–æ-–∫—Ä—É–∂–∫–æ–≤"""
    user_id = update.effective_user.id
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é
    user_manager = context.bot_data['user_manager']
    is_registered = await user_manager.is_registered(user_id)
    
    if not is_registered:
        await update.message.reply_text(
            "‚ùå –°–Ω–∞—á–∞–ª–∞ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–π—Å—è —Å –ø–æ–º–æ—â—å—é /start –∏ /setup"
        )
        return
    
    # –°–∫–∞—á–∏–≤–∞–µ–º –≤–∏–¥–µ–æ
    video_note = update.message.video_note
    bot = context.bot
    file = await bot.get_file(video_note.file_id)
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –Ω–∞—á–∞–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    processing_msg = await update.message.reply_text(
        "üé• –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –≤–∏–¥–µ–æ-–∫—Ä—É–∂–æ–∫...\n"
        "‚è≥ –ò–∑–≤–ª–µ–∫–∞—é –∫–∞–¥—Ä—ã –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ..."
    )
    
    try:
        # –°–∫–∞—á–∏–≤–∞–µ–º –≤–∏–¥–µ–æ
        video_bytes = await file.download_as_bytearray()
        logger.info(f"–°–∫–∞—á–∞–Ω–æ –≤–∏–¥–µ–æ: {len(video_bytes)} –±–∞–π—Ç")
        
        # –°–æ–∑–¥–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
        import config
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ª–∏ OpenCV
        try:
            import cv2
            use_real_analyzer = True
            logger.info("OpenCV –¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä")
        except ImportError:
            use_real_analyzer = False
            logger.warning("OpenCV –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–∫-–∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä")
        
        # –í—ã–±–∏—Ä–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
        # –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å OpenRouter API
        if use_real_analyzer:
            video_analyzer = VideoNoteAnalyzer(config)
        else:
            # Fallback –Ω–∞ –º–æ–∫, –µ—Å–ª–∏ OpenCV –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
            video_analyzer = MockVideoNoteAnalyzer()
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–∏–¥–µ–æ
        result = await video_analyzer.analyze_video_note(video_bytes, user_id)
        
        if not result:
            await processing_msg.edit_text(
                "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–∏–¥–µ–æ. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑."
            )
            return
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        analysis = result.get('analysis', result)  # Fallback –¥–ª—è —Å—Ç–∞—Ä–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞
        frames = result.get('frames', [])
        transcription = result.get('transcription', '')
        
        # 1. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if transcription:
            await update.message.reply_text(
                f"üé§ *–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∞—É–¥–∏–æ:*\n\n_{transcription}_",
                parse_mode='Markdown'
            )
        else:
            await update.message.reply_text(
                "üé§ _–ê—É–¥–∏–æ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∏–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å_",
                parse_mode='Markdown'
            )
        
        # 2. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã–µ –∫–∞–¥—Ä—ã
        if frames:
            await update.message.reply_text(
                f"üì∏ *–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(frames)} –∫–ª—é—á–µ–≤—ã—Ö –∫–∞–¥—Ä–æ–≤:*",
                parse_mode='Markdown'
            )
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–¥—Ä—ã –∫–∞–∫ –º–µ–¥–∏–∞-–≥—Ä—É–ø–ø—É (–¥–æ 10 —Ñ–æ—Ç–æ)
            from telegram import InputMediaPhoto
            import io
            
            media_group = []
            for i, frame_bytes in enumerate(frames[:10]):  # Telegram limit: 10 photos
                media_group.append(
                    InputMediaPhoto(
                        media=io.BytesIO(frame_bytes),
                        caption=f"–ö–∞–¥—Ä {i+1}/{len(frames)}"
                    )
                )
            
            await update.message.reply_media_group(media=media_group)
        
        # 3. –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
        from utils.formatters import format_video_note_analysis
        formatted_result = format_video_note_analysis(analysis)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
        await processing_msg.edit_text(
            formatted_result,
            parse_mode='Markdown'
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å–µ—Å—Å–∏—é (–¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ü–∏–π)
        session_manager = context.bot_data['session_manager']
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é (–∏—Å–ø–æ–ª—å–∑—É–µ–º file_id –≤–∏–¥–µ–æ –≤–º–µ—Å—Ç–æ photo_file_id)
        session_id = await session_manager.create_session(
            user_id,
            video_note.file_id
        )
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–µ—Å—Å–∏—é —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
        await session_manager.update_session(
            session_id,
            initial_analysis=analysis,
            status='pending'
        )
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        from core.state_machine import UserState
        state_manager = context.bot_data.get('state_manager')
        if state_manager:
            await state_manager.set_state(user_id, UserState.WAITING_CONFIRMATION)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–Ω–æ–ø–∫–∏
        from utils.keyboards import create_analysis_actions_keyboard
        keyboard = create_analysis_actions_keyboard()
        await update.message.reply_text(
            "–ß—Ç–æ –¥–∞–ª—å—à–µ?",
            reply_markup=keyboard
        )
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ: {e}", exc_info=True)
        await processing_msg.edit_text(
            f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}\n\n"
            "–ü–æ–ø—Ä–æ–±—É–π –∑–∞–ø–∏—Å–∞—Ç—å –≤–∏–¥–µ–æ –∑–∞–Ω–æ–≤–æ."
        )
